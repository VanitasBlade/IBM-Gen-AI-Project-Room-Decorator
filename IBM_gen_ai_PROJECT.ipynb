{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9Wj0K/UzK1Ov1608SPv/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanitasBlade/IBM-Gen-AI-Project-Room-Decorator/blob/main/IBM_gen_ai_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing related Libraries and Dependencies\n"
      ],
      "metadata": {
        "id": "dQCN_pL0n_A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers transformers accelerate safetensors\n",
        "!pip install -q streamlit pyngrok\n"
      ],
      "metadata": {
        "id": "R790m5-IKwBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionImg2ImgPipeline, StableDiffusionControlNetImg2ImgPipeline, ControlNetModel\n",
        "import torch\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "ymIdqeFsK1hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# ----------------------------------------\n",
        "# üõãÔ∏è Smart AI Room Decorator with Streamlit\n",
        "# ----------------------------------------\n",
        "# Dynamically chooses between Canny and Depth-based ControlNet pipelines\n",
        "# based on user-selected design mode (preserve layout vs full redesign)\n",
        "# ----------------------------------------\n",
        "\n",
        "# Configure Streamlit page\n",
        "st.set_page_config(page_title=\"üõãÔ∏è Smart AI Room Decorator\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üõãÔ∏è Smart AI Room Decorator\")\n",
        "st.markdown(\"\"\"\n",
        "Upload an image of a room and describe your dream space.\n",
        "This app **automatically switches models**:\n",
        "- ü™ë *Preserve layout & furniture*: ControlNet + Canny\n",
        "- üèóÔ∏è *Redesign empty room*: ControlNet + Depth for better furniture placement\n",
        "\"\"\")\n",
        "\n",
        "# Set device based on availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -------------------------------\n",
        "# üîß Load both ControlNet pipelines\n",
        "# -------------------------------\n",
        "@st.cache_resource\n",
        "def load_pipelines():\n",
        "    # Load Canny-based ControlNet (for preserving layout)\n",
        "    controlnet_canny = ControlNetModel.from_pretrained(\n",
        "        \"lllyasviel/control_v11p_sd15_canny\", torch_dtype=torch.float16\n",
        "    )\n",
        "    pipe_canny = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(\n",
        "        \"SG161222/Realistic_Vision_V5.1_noVAE\",\n",
        "        controlnet=controlnet_canny,\n",
        "        torch_dtype=torch.float16\n",
        "    ).to(device)\n",
        "\n",
        "    # Load Depth-based ControlNet (for full room redesigns)\n",
        "    controlnet_depth = ControlNetModel.from_pretrained(\n",
        "        \"lllyasviel/control_v11f1p_sd15_depth\", torch_dtype=torch.float16\n",
        "    )\n",
        "    pipe_depth = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(\n",
        "        \"SG161222/Realistic_Vision_V5.1_noVAE\",\n",
        "        controlnet=controlnet_depth,\n",
        "        torch_dtype=torch.float16\n",
        "    ).to(device)\n",
        "\n",
        "    return pipe_canny, pipe_depth\n",
        "\n",
        "# Load both pipelines\n",
        "pipe_canny, pipe_depth = load_pipelines()\n",
        "\n",
        "# ----------------------------------\n",
        "# üß† Helper: Generate Canny edge map\n",
        "# ----------------------------------\n",
        "def get_canny_image(image, size=(512, 512)):\n",
        "    image_resized = image.resize(size)\n",
        "    image_np = np.array(image_resized)\n",
        "    edges = cv2.Canny(image_np, 100, 200)\n",
        "    edges_rgb = np.stack([edges] * 3, axis=-1)  # convert to 3-channel RGB\n",
        "    return Image.fromarray(edges_rgb).convert(\"RGB\")\n",
        "\n",
        "# -----------------------------------\n",
        "# üß† Helper: Generate Depth map image\n",
        "# -----------------------------------\n",
        "def get_depth_image(image, size=(512, 512)):\n",
        "    from transformers import DPTFeatureExtractor, DPTForDepthEstimation\n",
        "\n",
        "    # Load depth model from HuggingFace\n",
        "    model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-hybrid-midas\").to(device)\n",
        "    processor = DPTFeatureExtractor.from_pretrained(\"Intel/dpt-hybrid-midas\")\n",
        "\n",
        "    image_resized = image.resize(size)\n",
        "    inputs = processor(images=image_resized, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        depth = outputs.predicted_depth.squeeze().cpu().numpy()\n",
        "\n",
        "    # Normalize and convert to RGB\n",
        "    depth = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    depth_rgb = np.stack([depth]*3, axis=-1)\n",
        "    return Image.fromarray(depth_rgb).convert(\"RGB\")\n",
        "\n",
        "# -----------------------------------\n",
        "# üì§ User Inputs\n",
        "# -----------------------------------\n",
        "uploaded_file = st.file_uploader(\"üì§ Upload a room image (JPG or PNG)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "design_mode = st.radio(\"üéØ Choose design goal:\", (\"ü™ë Preserve layout & furniture\", \"üèóÔ∏è Fill empty room with furniture\"))\n",
        "prompt = st.text_input(\"üìù Describe your dream room:\")\n",
        "\n",
        "# -----------------------------------\n",
        "# üîÅ Generate Redesign (once image + prompt are ready)\n",
        "# -----------------------------------\n",
        "if uploaded_file and prompt:\n",
        "    original_image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "\n",
        "    # Choose control method and pipeline\n",
        "    with st.spinner(\"üîÑ Generating control image...\"):\n",
        "        if design_mode == \"ü™ë Preserve layout & furniture\":\n",
        "            control_image = get_canny_image(original_image)\n",
        "            pipe = pipe_canny\n",
        "            strength = 0.75  # keep structure\n",
        "        else:\n",
        "            control_image = get_depth_image(original_image)\n",
        "            pipe = pipe_depth\n",
        "            strength = 1.0  # full creativity\n",
        "\n",
        "    # Generate redesigned room\n",
        "    with st.spinner(\"üé® Generating AI room redesign...\"):\n",
        "        result = pipe(\n",
        "            prompt=prompt,\n",
        "            image=original_image.resize((512, 512)).convert(\"RGB\"),\n",
        "            control_image=control_image.resize((512, 512)).convert(\"RGB\"),\n",
        "            strength=strength,\n",
        "            guidance_scale=7.5,\n",
        "            num_inference_steps=30\n",
        "        ).images[0]\n",
        "\n",
        "    # --------------------------\n",
        "    # üé≠ Display before & after\n",
        "    # --------------------------\n",
        "    st.markdown(\"### üé≠ Before and After\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.markdown(\"**üñºÔ∏è Original Room**\")\n",
        "        st.image(original_image.resize((512, 512)), use_container_width=True)\n",
        "    with col2:\n",
        "        st.markdown(\"**‚ú® Redesigned Room**\")\n",
        "        st.image(result.resize((512, 512)), use_container_width=True)\n"
      ],
      "metadata": {
        "id": "eS0EZXZUMERR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702efedc-c441-47ef-c114-5c6513a7f1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "import os\n",
        "\n",
        "# ‚úÖ Set your ngrok authtoken\n",
        "NGROK_AUTH_TOKEN = \"2zNLmftrSpRCnguytWvDaiIpqba_2ftvNENtR9A5uXLCRvawk\"\n",
        "os.system(f\"ngrok config add-authtoken {NGROK_AUTH_TOKEN}\")\n",
        "\n",
        "# üßπ Kill previous tunnels (avoid duplicate tunnels)\n",
        "ngrok.kill()\n",
        "\n",
        "# üßæ Optional: Clean logs\n",
        "if os.path.exists(\"/content/log.txt\"):\n",
        "    os.remove(\"/content/log.txt\")\n",
        "\n",
        "# üöÄ Run Streamlit in background and log output\n",
        "print(\"‚è≥ Starting Streamlit app...\")\n",
        "os.system(\"streamlit run app.py &> /content/log.txt &\")\n",
        "\n",
        "# ‚è± Wait for Streamlit to boot up\n",
        "time.sleep(10)  # <- increase this to 10+ seconds if models are heavy\n",
        "\n",
        "# üåç Start tunnel\n",
        "print(\"üîå Connecting via ngrok...\")\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(\"‚úÖ App is live! Visit:\")\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkKQWxNjMr7k",
        "outputId": "2cb2f57a-65e5-4edb-e4d1-3d930a8f9233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Starting Streamlit app...\n",
            "üîå Connecting via ngrok...\n",
            "‚úÖ App is live! Visit:\n",
            "NgrokTunnel: \"https://9e9d-34-143-130-20.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}